---
title: "3_Linear_Regression_Part_2"
author: "T.A. Meraxa"
date: "November, 2016"
output: html_document
---

### 3.4 Factors, Interactions and Weights

Formula       | Description
------------  |------------
y ~ a + x     | Model without interaction: indentical slopes with respect to x, but different intercepts with respect to a.
Y ~ a* x      | Model with interaction: the term a:x gives the difference in slopes compared with the reference category.
y ~ a/x       | Model with interaction: produces the same fitten values as the mdoel above but using a nested coefficient coding. An explicit slope estimate is computed for each category in a.
y ~ (a+b+c)^2 | Model with all two-way interactions(excluding three way interaction).

#### Interactions

```{r}
# Let's consider an interaction between `ethnicity` and `education`
cps_int <- lm(log(wage) ~ experience + I(experience^2) + education * ethnicity, data = CPS1988)
coeftest(cps_int)
```

Resuts indicated that the interaction term is significant at the 5% level

#### Separate regression for each level

As a further variation, it may be necessary to fit separate regression for African-Americans and Caucasians. It can be computed using two separate `lm` objects

```{r}
cps_sep <- lm(log(wage) ~ ethnicity / (experience + I(experience^2) + education) -1, data = CPS1988)
summary(cps_sep)

# For compactness
cps_sep_cf <- matrix(coef(cps_sep), nrow =2)
rownames(cps_sep_cf) <- levels(CPS1988$ethnicity)
colnames(cps_sep_cf) <- names(coef(cps_lm))[1:4]
cps_sep_cf
```

This shows that the effects of education are similar for both groups, but the remaining coefficients are somewhat smaller in absolute size for African-Americans

```{r}
# A comparison of the new models with the first one yields
anova(cps_sep, cps_lm)
```

#### Change of reference category

In any regression containing unordered factor, R by default uses the first level of factor as the reference category. In `CPS1988`, `"cauc"` is the reference category for `ethnicity`, while `"northeast"` is the reference category for `region`. Bierens and Ginther (2001) employ `"south"` as the reference category for region. 

```{r}
CPS1988$region <- relevel(CPS1988$region, ref ="south")
cps_region <- lm(log(wage) ~ ethnicity + education + experience + I(experience^2) + region, data = CPS1988)
coef(cps_region)
```

#### Weighted least squared

Cross-section regressions are often plagued by heteroskedasticity. One of the remedies is to use weighted least squares (WLS)

```{r}
#add Journals data
data("Journals")
journals <- Journals[, c("subs", "price")]
journals$citeprice <- Journals$price/Journals$citations
summary(journals)

jour_wls1 <- lm(log(subs) ~ log(journals$citeprice), data = Journals, weights = 1/journals$citeprice^2)

jour_wls2 <- lm(log(subs) ~ log(journals$citeprice), data = Journals, weights = 1/journals$citeprice)

summary(jour_wls1)
summary(jour_wls2) # yields a regression with weights in the form 1/z[i]
```

Plotting a comparison between OLS and WLS

```{r}
plot(log(subs) ~ log(citeprice), data = journals)
abline(jour_lm)
abline(jour_wls1, lwd = 2, lty = 2)
abline(jour_wls2, lwd = 2, lty = 3)
legend("bottomleft", c("OLS", "WLS1", "WLS2"), lty = 1:3, lwd = 2, bty = "n")
```

#### Feasible generalized least squares (FGLS)

E(epsilon^2i|xi) = sigma^2x^2i = exp(lambda1+lambda2logxi)

When you are not sure as to which form of the skedastic function to use and would prefer to estimate it from the data. This is estimated by regressing the logarithm of the squared residuals from the OLS regression on the logarithm of `citeprice` and a constant.

```{r}
# Use fitted values of this auxilarry regression as the weights in the model of interesst
auxreg <- lm(log(residuals(jour_lm)^2) ~ log(citeprice), data = journals)

# Create the model
jour_fgls1 <- lm(log(subs) ~ log(citeprice), weights = 1/exp(fitted(auxreg)), data = journals)

# Summary 
summary(jour_fgls1)

# It is possible to iterate further, yielding a second variant of the FGLS approach. A compact solution makes use of a while loop:
gamma2i <- coef(auxreg)[2]
gamma2 <- 0

while(abs((gamma2i - gamma2)/gamma2) > 1e-7) {
  gamma2 <- gamma2i
  fglsi <- lm(log(subs) ~ log(citeprice), data = journals,
  weights = 1/citeprice^gamma2)
  gamma2i <- coef(lm(log(residuals(fglsi)^2) ~
  log(citeprice), data = journals))[2]
}
  
# Create the model
jour_fgls2 <- lm(log(subs) ~ log(citeprice), data = journals, weights = 1/citeprice^gamma2)

# Summary
summary(jour_fgls2)

```

The loop specifies that as long as the relative change of the slope coefficient exceeds 10^-7 in absolute value, the interation is continued.

### 3.5 Linear Regression with Time Series Data

In econometrics, time series regressions are often fitten by OLS. However, this is typically not the case for time series data, which are more conveniently stored in one of R's time series classes. Using `lm` with "ts" has two drawbacks: (1) for fitted values or resoduals, the time series properties are by default not preserved, and (2) lags or differences cannot directly be specifiedin the model formula.

The solution is to do additional computations "by hand". Alternatively, the package dynlm (Zeileis, 2008) provides the function dynlm, which helps to overcome the problems desired above. This method allows formulas such as `d(y) ~ L(d(y)) + L(x, 4)`, describing a regression of the first differences of a variable y on its first difference lagged by one period and on the fourth lag of a variable x.

As illustration, we will follow Greene (2003), and consider different forms for a consumption function based on quarterly US macroeconomic data from 1950 through 2004 as provided in the data set `USMacroG`.

```{r}
install.packages("dynlm")
library(dynlm)
data("USMacroG")


# Visualize the disposable income dpi and consumption
plot(USMacroG[, c("dpi", "consumption")], lty = c(3,1), plot.type = "single", ylab="")
legend("topleft", legend = c("income", "consumption"), lty = c(3,1), bty = "n")
```

Greene (2003) considers two models:

Consumption = Beta1 + Beta2dpi + Beta3dpi[i-1] + epsilon[i]
~ a distributed lag model, conssumption responds to change in income only over two periods.

Consumption = Beta1 + Beta2dpi + Beta3consumption[i-1] + epsilon[i]
~ autoregressive distributed lag model, the effects of income changes persist due to the autoregressive specification.

The models can be fitted to by `dynlm()` as follows

```{r}
# Fitting the model
library("dynlm")
cons_lm1 <- dynlm(consumption ~ dpi + L(dpi), data = USMacroG)
cons_lm2 <- dynlm(consumption ~ dpi + L(consumption), data = USMacroG)

# Summary
summary(cons_lm1)
summary(cons_lm2)

# The RSS of the models can be obtained as follows:
deviance(cons_lm1)
deviance(cons_lm2)

# The two fitted models can be visualed using the folloiwing code:
plot(merge(as.zoo(USMacroG[,"consumption"]), fitted(cons_lm1),
  fitted(cons_lm2), 0, residuals(cons_lm1),
  residuals(cons_lm2)), screens = rep(1:2, c(3, 3)),
  lty = rep(1:3, 2), ylab = c("Fitted values", "Residuals"),
  xlab = "Time", main = "")
legend(0.05, 0.95, c("observed", "cons_lm1", "cons_lm2"),
  lty = 1:3, bty = "n")
```

#### Encompassing test

To discriminate between these two competing nonnested models, we consider an encompassing test. The encompassing approach to comparing two nonnested models is to transform the problem into a situation we can already deal with: comparing nested models. The idea is to fit the encompassing model comprising all regressors from both competing models, in our case the autoregressive distributed lag (ADL) model

```{r}
# Model
cons_lmE <- dynlm(consumption ~ dpi + L(dpi) + L(consumption), data = USMacroG)
```

and then to compare each of the two nonnested models with the encompassing models. Now if one of the models is not significantly worse than the encompassing modell while the other is, this test would favor the former model over the latter. As illustrated in the previous sections, nested models can be compared with `anova()`, and the tests can be carried out in one go.

```{r}
# Model
anova(cons_lm1, cons_lmE, cons_lm2)
```

The first F test compares the model `cons_lm1` with the encompassing model `cons_lmE`, and the second F test compares `cons_lmE` and `cons_lm2`. Both models perform significantly worse compared with the encompassing model, although the F statistic is much smaller for `cons_lm2`.

Instead of computing the encompassing model by hand and then by calling anova(), the function encomptest() from the lmtest package can be used. This simplifies the call to

```{r}
# Function encomptest()
encomptest(cons_lm1, cons_lm2)
```

### 3.6 Linear Regression with Panel Data

The package plm (Croissant & Millo, 2005) contains the relevant fitting functions and methods for panel data.

#### Static linear models

For illustrating the basic fixed- and random-effects methods, we use the well known Grunfeld data (Grunfeld 1958) comprising 20 annual observations on the three variables of real gross investement (invest), real value of the firm (value), and real value of the capital stock (capital) for 11 large US firms for the year 1935-1954.

The main difference between cross-sectional data and panel data is that panel data have an internal structure, indexed by a two-dimensional array, which must be communicated into the fitting function.





